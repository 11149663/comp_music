---
title: "My Computational Musicology Portfolio"
author: "Jason Z."
date: "Feb/Mar 2021"
output:
  flexdashboard::flex_dashboard:
    storyboard: true
    theme: flatly
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
# stackoverflow.com/questions/33402920/using-ggplot2-and-special-characters
# switch between reading error messages and reading track labels
# Sys.setlocale("LC_ALL", "Japanese") 
# options(encoding = "UTF-8")
```

```{r, include = FALSE}
## Loading libraries
library(tidyverse) 
library(spotifyr)
library(compmus)
library(plotly)
library(flexdashboard)
library(readxl)
library(grid)
library(gridExtra)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(kknn)
library(C50)
library(ranger)
library(RColorBrewer)
library(Polychrome)
library(cowplot)
```

```{r, include = FALSE}
# Retrieve my portfolio playlists
y2011 <- get_playlist_audio_features("", "544c7nycI0F40aO2dZkWXm")
y2012 <- get_playlist_audio_features("", "4GRDx8ryZypvBaZFSh4kWa")
y2013 <- get_playlist_audio_features("", "1ys2ATlrbdoh9JfT8fKToA")
y2014 <- get_playlist_audio_features("", "1yqM9ChrxHxbOJUiYbFPLZ")
y2015 <- get_playlist_audio_features("", "6WmvRZEr7bWnCscOFVhNJB")
y2016 <- get_playlist_audio_features("", "60OfN9aW1vJHvhqUOEVxMQ")
y2017 <- get_playlist_audio_features("", "4c9iuV5x9M9FHumOjGRfg0")
y2018 <- get_playlist_audio_features("", "3gIybzPIbiJSzoeU7lDyDj")
y2019 <- get_playlist_audio_features("", "0MIzuDtEA31PrJ68ZXdeqx")
y2020 <- get_playlist_audio_features("", "1HN2I323QTNX5jofgP8fiC")
```

```{r, include = FALSE}
# Mutate into category:year
combined_years <- 
  bind_rows(
    y2011 %>% mutate(category = "2011", mode = ifelse(mode == 0, "Minor", "Major")),
    y2012 %>% mutate(category = "2012", mode = ifelse(mode == 0, "Minor", "Major")),
    y2013 %>% mutate(category = "2013", mode = ifelse(mode == 0, "Minor", "Major")),
    y2014 %>% mutate(category = "2014", mode = ifelse(mode == 0, "Minor", "Major")),
    y2015 %>% mutate(category = "2015", mode = ifelse(mode == 0, "Minor", "Major")),
    y2016 %>% mutate(category = "2016", mode = ifelse(mode == 0, "Minor", "Major")),
    y2017 %>% mutate(category = "2017", mode = ifelse(mode == 0, "Minor", "Major")),
    y2018 %>% mutate(category = "2018", mode = ifelse(mode == 0, "Minor", "Major")),
    y2019 %>% mutate(category = "2019", mode = ifelse(mode == 0, "Minor", "Major")),
    y2020 %>% mutate(category = "2020", mode = ifelse(mode == 0, "Minor", "Major"))
  )

combined_tempo <-
  bind_rows(
    y2011 %>% mutate(category = "2011-2012"),
    y2012 %>% mutate(category = "2011-2012"),
    y2013 %>% mutate(category = "2013-2014"),
    y2014 %>% mutate(category = "2013-2014"),
    y2015 %>% mutate(category = "2015-2016"),
    y2016 %>% mutate(category = "2015-2016"),
    y2017 %>% mutate(category = "2017-2018"),
    y2018 %>% mutate(category = "2017-2018"),
    y2019 %>% mutate(category = "2019-2020"),
    y2020 %>% mutate(category = "2019-2020")
  )
```

```{r, include = FALSE}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  
```

**Introduction** {.storyboard}
===============================================================

### Diving into my **10-years** worth of last.fm **music log** {data-commentary-width=300}
 
<span style="text-decoration:underline">**What is your corpus, why did you choose it, and what do you think is interesting about it?**</span>

Last.fm is an online music database, a music recommender system, and a social 
networking service, which was founded in the days when MSN, Myspace, and
Runescape were still a thing. In general, the website offers a plugin for you 
to install on your PC and phone, which can track your listening behaviour. 
One listen, a *scrobble*, is then transferred (or "scrobbled") to the database 
and displayed on your personal profile. Based on the collected data, it could 
also recommend you new music to discover or connect you to people with similar music taste.
Although the social aspects have been watered down, I've still been using their 
service ever since June 2011 ([my profile](https://last.fm/user/wutsmainaem)). 
With a *vast* amount of data up for grabs, it would be a waste to leave the data 
as it is. That is why I'm interested in learning more about 
**how my listening has changed over the years**. 

As of December 31st of 2020, I have approximately over 97.000 registered scrobbles 
and 24.000 unique tracks over the course of ten years. The size is too big for 
the scope of this course, so I will be limiting to a set number of top tracks 
each year. This makes it easier to explore the data without losing much overview 
of my general listening behaviour.

<span style="text-decoration:underline">**What are the natural groups or comparison points in your corpus and what is expected between them?**</span>

My corpus will be divided in years **from June 2011 to the end of 2020**. 
According to a [NYTimes-article](https://www.nytimes.com/2018/02/10/opinion/sunday/favorite-songs.html), our musical taste is established during our (formative) teenage years. If that is the case,
I'd expect that a certain music style from my teenage years would show up throughout my corpus.
Apart from that, I still expect changes in my music preferences, as I grow older.

<span style="text-decoration:underline">**How representative are the tracks in your corpus for the groups you want to compare?**</span>

I used [Spotlistr](https://www.spotlistr.com/search/lastfm-top-for-time-period) and [Soundiiz](https://soundiiz.com/)
to transfer **60 tracks per year** from my last.fm profile to Spotify. 
As I've been listening to albums more than separate songs at some point in life,
I decided to grab **top 10 tracks** and the remaining **50 tracks between #11-100** 
at random to broaden the scope. Sometimes the tool didn't pick the correct 
track due to changes in the metadata, for which I adjusted manually. Examples
include band name changes, such as 'Viet Cong' to 'Preoccupations' and 
'Andrew Jackson Jihad' to 'AJJ'. If a top 10 song was missing, then the next song 
was selected (#11 and so on). I also removed tracks that are considered as intros
or interludes.

My corpus comes with a few limitations:

-  I've only started using the last.fm plugin on my smartphone since 
February 2015. Before then, I relied on my PC/laptop to log my scrobbles, which
makes the data between 2011 and 2014 less accurate.

- Possible under-representation of certain music styles in my 60 track selections. 
As a simple example: song 1 of style A has 100 scrobbles, song 2 and 3 of style B 
have 60 each. In total, style A has 100 scrobbles, whereas style B has 120, which 
is more than style A.

- On a handful occasions, I fell asleep with my music and last.fm still on.

<span style="text-decoration:underline">**Identify several tracks in your corpus that are either extremely typical or atypical**</span> \

<span style="text-decoration:underline">Typical songs:</span> \
Processed by the Boys - Protomartyr: Musical styles (*post-punk*) from songs like this one have dominated my corpus since 2011. \
Ferrum - Chihei Hatakeyama: Typical music (*ambient*) I listen to when I need to focus during work or study (especially since university). \ \

<span style="text-decoration:underline">Atypical songs:</span> \
Setsuyakuka - Tricot: Classified as *math rock*, a genre which gained prominence in my corpus starting from 2016. \
Rosebud - U.S. Girls: I don't listen to a lot of music that is considered '*pop*'. A track such as this one, however, stands high in my last.fm charts.\
Gruppa Krovi - Kino: Alongside Tricot the only two only two *non-English* singing music groups in my all-time top 10.

***
![Logo of last.fm](lastfm.jpg){width=100%}

View my corpus per year:

- 2011
- 2012
- 2013
- 2014
- 2015
- 2016
- 2017
- 2018
- 2019
- 2020

**Track-level features** {.storyboard}
===============================================================

### A1: **How much** have I listened to music **over the years**? {data-commentary-width=500}

```{r, echo = FALSE}
scrobbles <- read_excel("C:/Users/Jason/Desktop/CompMus/Scrobbles_year.xlsx")

# https://stackoverflow.com/questions/9227389/ordering-stacks-by-size-in-a-ggplot2-stacked-bar-graph
scrobbles$Group <- reorder(scrobbles$Group, scrobbles$Scrobbles)
scrobbles$Group <- factor(scrobbles$Group, levels=rev(levels(scrobbles$Group)))

# https://stackoverflow.com/questions/34164687/r-how-to-change-the-color-scheme-14-colors-needed-in-ggplot
# mycolors = c(brewer.pal(name="Dark2", n = 8), brewer.pal(name="Paired", n = 12), 
#             brewer.pal(name="Set2", n = 8))

# https://stackoverflow.com/questions/15282580/how-to-generate-a-number-of-most-distinctive-colors-in-r
n <- 38
qual_col_pals = brewer.pal.info[brewer.pal.info$category == 'qual',]
col_vector = unlist(mapply(brewer.pal, qual_col_pals$maxcolors, rownames(qual_col_pals)))
```

```{r, echo = FALSE}
listens <- scrobbles %>%
  ggplot(aes(x = Year, y = Scrobbles, fill = Group, color = Group)) +
  ggtitle("Number of recorded 'scrobbles' per year including top 5 most listened artists") +
  geom_col(width = 0.9, alpha = 0.8) +
  labs(x="year", y="number of scrobbles") + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1), legend.position = "none") +
  scale_fill_manual(values = col_vector) +
  scale_color_manual(values = col_vector) + 
  
  geom_vline(xintercept = 3.9, linetype = 2, size = 0.3, alpha = 0.3) +
    annotate(geom = "text", x = 3.9, y = 11000, label = "<b>May 2014</b>:\n'Eindexamens'", size = 4) + 
  
  geom_vline(xintercept = 4.65, linetype = 2, size = 0.3, alpha = 0.3, color = "red") +
    annotate(geom = "text", x = 4.65, y = 13000, label = "<b>Jan 2015</b>:\nNew Phone + Spotify", size = 4) +

  geom_vline(xintercept = 5.2, linetype = 2, size = 0.3, alpha = 0.3) +
    annotate(geom = "text", x = 5.2, y = 15000, label = "<b>Sep 2015</b>:\nStart UvA", size = 4) +

  geom_vline(xintercept = 8.1, linetype = 2, size = 0.3, alpha = 0.3) +
    annotate(geom = "text", x = 8.1, y = 13000, label = "<b>Aug 2018</b>:\nMoved to Hong Kong", size = 4) +
  
  geom_vline(xintercept = 9.8, linetype = 2, size = 0.3, alpha = 0.3) +
    annotate(geom = "text", x = 9.8, y = 11000, label = "<b>Mar 2020</b>:\nCovid-19 Pandemic", size = 4) +
  
  annotate(geom = "text", x = 1, y = 9073, label = "Total: 9373", size = 3.5) +
  annotate(geom = "text", x = 1, y = 3100, label = "Top 5: 2800 (29.9%)", size = 2.5) +
  
  annotate(geom = "text", x = 2, y = 7483, label = "Total: 7783", size = 3.5) +
  annotate(geom = "text", x = 2, y = 2542, label = "Top 5: 2242 (28.8%)", size = 2.5) +
  
  annotate(geom = "text", x = 3, y = 6301, label = "Total: 6601", size = 3.5) +
  annotate(geom = "text", x = 3, y = 2097, label = "Top 5: 1797 (27.2%)", size = 2.5) +
  
  annotate(geom = "text", x = 4, y = 7280, label = "Total: 7580", size = 3.5) +
  annotate(geom = "text", x = 4, y = 1736, label = "Top 5: 1436 (19.0%)", size = 2.5) +
  
  annotate(geom = "text", x = 5, y = 10278, label = "Total: 10578", size = 3.5) +
  annotate(geom = "text", x = 5, y = 2802, label = "Top 5: 2502 (23.7%)", size = 2.5) +
  
  annotate(geom = "text", x = 6, y = 17473, label = "Total: 17773", size = 3.5) +
  annotate(geom = "text", x = 6, y = 4216, label = "Top 5: 3916 (22.0%)", size = 2.5) +
  
  annotate(geom = "text", x = 7, y = 8999, label = "Total: 9299", size = 3.5) +
  annotate(geom = "text", x = 7, y = 1841, label = "Top 5: 1541 (16.6%)", size = 2.5) +
  
  annotate(geom = "text", x = 8, y = 7025, label = "Total: 7325", size = 3.5) +
  annotate(geom = "text", x = 8, y = 1739, label = "Top 5: 1439 (19.6%)", size = 2.5) +
  
  annotate(geom = "text", x = 9, y = 6085, label = "Total: 6385", size = 3.5) +
  annotate(geom = "text", x = 9, y = 1722, label = "Top 5: 1422 (22.3%)", size = 2.5) +
  
  annotate(geom = "text", x = 10, y = 4192, label = "Total: 4492", size = 3.5) +
  annotate(geom = "text", x = 10, y = 1404, label = "Top 5: 1104 (24.6%)", size = 2.5)

ggplotly(listens)
```

***

*The interactive barplot shows how many scrobbles were recorded from June 11th,*
*2011 to December 31st, 2020, including the totals at the top of each bar.* 
*Zooming in on the bottom of the bars, you can find the top 5 most listened artists* 
*of each year. Also included are events that could have influenced my listening behaviour.*

Looking at all my recorded scrobbles from start to finish, you can observe that it increased
significantly in [2015](https://www.last.fm/user/wutsmainaem/library/artists?from=2015-01-01&rangetype=year), after which it **peaked in [2016](https://www.last.fm/user/wutsmainaem/library/artists?from=2016-01-01&rangetype=year)** at 17773. As I mentioned in the previous slide, this increase can be explained by the fact that I started using the last.fm plugin on my phone, after I had purchased one which supported the plugin (from 249 in December, 2014 to 1635 in January, 2015). Another possible reason for the increase is that it marked a **new chapter as a university student**. It was during this time that I spent more time listening to music during study sessions, and made effort to explore new music by spending (too much) on live music events.

From here on out, scrobbles declined continuously down to 4492 in [2020](https://www.last.fm/user/wutsmainaem/library?from=2020-01-01&rangetype=year). 
It seems that the COVID-19 pandemic had an influence on my scrobbles, as the 6-month average following the lockdown in March was around 375, whereas the average was 540 six months prior.

On a surface level, other interesting developments can be observed when looking at the top 5 most listened artists over the years. **In 2011 and 2012**, my top 5s were **dominated by UK artists** (9 out of 10). The top 5s of **2013/2014 diversified** with artists coming from other places than the UK (4/10). My exposure to **music produced in East Asia** has had a noticeable effect on my top 5s starting from late 2018. This kind of music was so dominant that it **overtook the entire top 5 in 2019** and most of 2018 and 2020.

### A2: How did my **music preferences** change over time based on **Spotify track features**? {data-commentary-width=500}

```{r, include = FALSE}
y2020 %>%
  summarise(
    mean_acousticness = mean(acousticness),
    mean_danceability = mean(danceability),
    mean_energy = mean(energy),
    mean_instrumentalness = mean(instrumentalness),
    mean_liveness = mean(liveness),
    mean_speechiness = mean(speechiness),
    mean_valence = mean(valence)
  )

data_means <- read_excel("C:/Users/Jason/Desktop/CompMus/mean_features.xlsx")
```

```{r, echo = FALSE}

mean_progress <- data_means %>%
  ggplot(aes(x = Year)) +
  ggtitle("Mean Spotify Audio Features per year") +

  geom_line(aes(y = Acousticness), group = 1, color = "red") +
  geom_point(aes(x=Year, y=Acousticness), col='red') +
  
  geom_line(aes(y = Danceability), group = 1, color = "orange") + 
  geom_point(aes(x=Year, y=Danceability), col='orange') +
  
  geom_line(aes(y = Energy), group = 1, color = "brown") +
  geom_point(aes(x=Year, y=Energy), col='brown') +
  
  geom_line(aes(y = Instrumentalness), group = 1, color = "green") +
  geom_point(aes(x=Year, y=Instrumentalness), col='green') +
  
  geom_line(aes(y = Liveness), group = 1, color = "blue") +
  geom_point(aes(x=Year, y=Liveness), col='blue') +
  
  geom_line(aes(y = Speechiness), group = 1, color = "purple") +
  geom_point(aes(x=Year, y=Speechiness), col='purple') +
  
  geom_line(aes(y = Valence), group = 1) +
  geom_point(aes(x=Year, y=Valence)) +
  
  labs(x="year", y="feature level [0 - 1]") + 
  theme(axis.text.x = element_text(angle = 60, hjust = 1), legend.position="right")
  
ggplotly(mean_progress)

```


***

Spotify offers a number of [track-level features](https://developer.spotify.com/documentation/web-api/reference/#object-audiofeaturesobject), 
which are used to characterize tracks that are available on their platform.
The plot on the left shows how these features have developed over time 
by calculating the means of the selected 60 tracks per year.

It looks like **speechiness** and **liveness** did not change much.
The former reflects the fact that I am (proportionally) **not much of a rap/hip-hop** 
**listener**, as this type of music requires values between 0.33 and 0.66. **Valence**
rose slightly early on, but stabilized around the middle at 0.5, whereas **energy**
experienced a noticiable shift upwards in 2016. More on this will follow in
the next slide.

**Acousticness** increased steadily in the early years, but declined after 2014
and did not reach higher than 0.2 since then.
One feature seems to have increased permanently, which is **instrumentalness**,
hovering mostly above 0.3 since 2015. This change could be explained by a **growth
in listening to instrumental music**, such as 
[Toe](https://www.last.fm/user/wutsmainaem/library/music/toe) and 
[GoGo Penguin](https://www.last.fm/user/wutsmainaem/library/music/GoGo+Penguin).
Another music genre that could've influenced the increased instrumental levels around 2015 
is **ambient**([Klara Lewis](https://www.last.fm/user/wutsmainaem/library/music/Klara+Lewis), 
[Ryuichi Sakamoto](https://www.last.fm/user/wutsmainaem/library/music/%E5%9D%82%E6%9C%AC%E9%BE%8D%E4%B8%80)),
as this was **my preferred genre during study sessions**. Also, the introduction of this genre could have pushed the **acousticness** levels further down since 2015.


### A3: Selected tracks are mainly **high in energy and diverse in valence** {data-commentary-width=500}

```{r, echo = FALSE}
valence_vs_energy <- combined_years %>%
  ggplot(aes(x = valence,
             y = energy,
             color = mode,
             size = instrumentalness,
             label = track.name)) +
  facet_wrap(~category) +
  geom_point(position = 'jitter', 
             alpha = 0.6) +
  geom_rug(size = 0.20) +
  ggtitle("Track-level feature comparison: Energy vs Valence vs Instrumentalness vs Mode") +
  theme_light() +
  scale_color_manual(values = c("Minor" = "#227788", "Major" = "#DD8877"),
                     guide = "legend") +
  scale_x_continuous(breaks = c(0, 0.50, 1),
                     minor_breaks = NULL) +
  scale_y_continuous(breaks = c(0, 0.50, 1),
                     minor_breaks = NULL) +
  scale_size_continuous(range = c(0.5, 5),
                        guide = "none") +
  geom_text(aes(x = valence, 
                y = energy, 
                label = label),
            data = tibble(label = c("Jùhachi"), 
                          category = c("2015"), 
                          valence = c(0.65),
                          energy = c(0.17)
                          ),
            color = "darkred",
            size = 3,
            family = "mono"
  )
  

ggplotly(valence_vs_energy)
```
***
![Spotify's energy and valence translated into four moods](mood.jpg){width=30%}

*The 'moods' of each track in every year can be presented by plotting the energy feature*
*against valence. Instrumentalness (size) and mode (colour) are displayed in the graphs as well.*
*The plot is made interactive, enabling you to zoom in on individual tracks.*

Overall, most songs in every year skew towards high energy levels (> 5.0), especially between 2016 and 2020.
Valence on the other hand shows a wider range, spanning across the entire spectrum. From this can be concluded
that the music I listened to in the past ten years are **mostly happy or angry in general**.

An interesting observation is that my listening habits gradually became **'sadder' from 2012 to 2014**. What's also striking is that my tracks **rarely** go deep into the '**relaxed**' quadrant with the exception of one song in 2015 (*Jùhachi*). Looking at the size of each point, you can clearly see that the instrumentalness increased substantially from 2015 as mentioned earlier. 

Based on these three visualizations, my logs can be categorized into (give or take) four periods:

- 'Mid-VWO'-era: UK-produced music (see A1)
- 'Late-vwo'-era: early diversity (A1), sadder music (A3)
- 'UvA'-era: most recorded scrobbles (A1), peak energy (A2), increase instrumentalness (A2)
- 'Post-HK'-era: music produced in East Asia (A1)

It seems that there's one particlar genre in my corpus that keeps coming back throughout the years, namely post-punk. In the corpus, this genre is represented by [Joy Division](https://en.wikipedia.org/wiki/Joy_Division) (Mid-VWO), [Kino](https://en.wikipedia.org/wiki/Kino_(band)) (Late-VWO), [Preoccupations](https://en.wikipedia.org/wiki/Preoccupations) (UvA), and [Protomartyr](https://en.wikipedia.org/wiki/Protomartyr_(band)) (UvA/Post-HK). I assume that this is what the NYTimes-writer meant with musical taste peaking as teens. Therefore, I will be examining the most listened song of each band in the following slides.

**Audio Analysis** {.storyboard}
===============================================================

### B1: Investigating the scope of my outliers in **chromagrams** {data-commentary-width=300}

```{r, include=FALSE}

# JUHACHI 2FghAESlnAFukLy5j2Ascp
# CHIHEI 4NV9wYTFbFuOndIUUyE5Pi
# BOLT 7DNRAyfqNpN0qzrS5JmJwY

# JOY 1Bq65xKgu0kjSUMUlfWyPl (Transmission)
# KINO 4g87T7h8coshsA1zJjFFbG (A Star Called Sun)
# VIET 3d5lGpqxg1cMEYrgTaGxZy (Continental Shelf)
# PROTO 6hVVhORwKxGgJ9PC2jaA2R (Processed by the Boys)
# TOE 0wJ2HYa7Do5nZYpnysJ3xd (C) high instrumentalness - math rock
# CHIHEI 4NV9wYTFbFuOndIUUyE5Pi (Far) high instrumentalness - ambient


joy_chroma <-
  get_tidy_audio_analysis("1Bq65xKgu0kjSUMUlfWyPl") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

joy_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>% # euclidean
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Transmission by Joy Division") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

kino_chroma <-
  get_tidy_audio_analysis("4g87T7h8coshsA1zJjFFbG") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

kino_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>% # euclidean
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("A Star Called Sun by Kino") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

viet_chroma <-
  get_tidy_audio_analysis("3d5lGpqxg1cMEYrgTaGxZy") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

viet_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>% # euclidean
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Continental Shelf by Preoccupations") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

proto_chroma <-
  get_tidy_audio_analysis("6hVVhORwKxGgJ9PC2jaA2R") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

proto_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>% # chebyshev
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Processed by the Boys by Protomartyr") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

toe_chroma <-
  get_tidy_audio_analysis("0wJ2HYa7Do5nZYpnysJ3xd") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

toe_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("C by Toe") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()

chihei_chroma <-
  get_tidy_audio_analysis("4NV9wYTFbFuOndIUUyE5Pi") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

chihei_chroma %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  ggtitle("Far from the Atmosphere by Chihei H.") +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude") +
  theme_minimal() +
  scale_fill_viridis_c()
```

```{r, include=FALSE}

#plot_grid(joy_p, kino_p, viet_p, proto_p, toe_p, chihei_p,
#          labels = c("1a", "1b", "1c", "2a", "2b", "2c"),
#          nrow=2)

```

![Chromagrams](chroma.jpg){width=100%}

***

Outlier: Song's very reliant on silence with occasional ...

Things to consider: 
Most listened song vs favourite song of 2020.
Compare multiple low valence/energy songs and see if they have something in common.

Song by Chihei Hatakeyama is interesting, as it mostly dominated by major notes.

### B2: Self-similarity Matrices {data-commentary-width=300}

```{r, include=FALSE}

# JOY 1Bq65xKgu0kjSUMUlfWyPl (Transmission) heel veel korte herhalingen
# KINO 4g87T7h8coshsA1zJjFFbG (A Star Called Sun) enige structuur
# VIET 3d5lGpqxg1cMEYrgTaGxZy (Continental Shelf)
# PROTO 6hVVhORwKxGgJ9PC2jaA2R (Processed by the Boys)
# TOE 0wJ2HYa7Do5nZYpnysJ3xd (C) high instrumentalness - math rock
# CHIHEI 4NV9wYTFbFuOndIUUyE5Pi (Far) high instrumentalness - ambient, helemaal niets in te herkennen

boys <-
  get_tidy_audio_analysis("1Bq65xKgu0kjSUMUlfWyPl") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(pitches = map(segments, compmus_summarise, pitches,
                       method = "rms", norm = "euclidean")) %>%
  mutate(timbre = map(segments, compmus_summarise, timbre,
                     method = "rms", norm = "euclidean"))
bind_rows(
  boys %>% 
    compmus_self_similarity(pitches, "cosine") %>% 
    mutate(d = d / max(d), type = "Chroma"),
  boys %>% 
    compmus_self_similarity(timbre, "cosine") %>% 
    mutate(d = d / max(d), type = "Timbre")
  ) %>%
  mutate() %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  ggtitle("Far from the Atmosphere by Chihei H.") +
  facet_wrap(~type) +
  theme_classic() +
  scale_fill_viridis_c() +
  labs(x = "", y = "")
```

![Self-Similarity Matrices](ssm.jpg){width=100%}

***
[W08: Draft]

On the left, you see two self-similarity matrices displaying chroma and timbre 
features of Processed by the Boys by Protomartyr (top track of 2020). 
As for the settings:segments are set in bars, applied normalization and summary 
statistics are euclidean and root mean square, respectively. The darker the 
colour brightness, the more similar the segments are compared to segments before 
it in time.

Findings:

- ...

- ...

Things to consider:
Compare above to top track of years 2016, 2018 (Rosebud) or other/more years.


### B3: Chordograms {data-commentary-width=300}

```{r, include = FALSE}

circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```


```{r, include = FALSE}
rosebud_chordkey <-
  get_tidy_audio_analysis("1Rtcq2RErgV3NuQvKdCNf6") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )

boys_chordkey <-
  get_tidy_audio_analysis("6hVVhORwKxGgJ9PC2jaA2R") %>%
  compmus_align(sections, segments) %>%
  select(sections) %>%
  unnest(sections) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      )
  )
```


```{r, include = FALSE}
rosebud_key <- rosebud_chordkey %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "aitchison",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

rosebud_chord <- rosebud_chordkey %>% 
  compmus_match_pitch_template(
    chord_templates,       # Change to chord_templates if desired
    method = "manhattan",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  theme(axis.text=element_text(size=5))

boys_key <- boys_chordkey %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if desired
    method = "aitchison",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "")

boys_chord <- boys_chordkey %>% 
  compmus_match_pitch_template(
    chord_templates,       # Change to chord_templates if desired
    method = "manhattan",  # Try different distance metrics
    norm = "manhattan"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  scale_fill_viridis_c(guide = "none") +
  theme_minimal() +
  labs(x = "Time (s)", y = "") +
  theme(axis.text=element_text(size=5))

```

```{r, echo = FALSE}
grid.arrange(arrangeGrob(rosebud_chord, top = grid::textGrob("Rosebud", hjust = 0.15), left = "Chordogram"),
             arrangeGrob(boys_chord, top = grid::textGrob("Processed by the Boys", hjust =0.21)),
             arrangeGrob(rosebud_key, left="Keygrams"), boys_key, ncol=2, nrow=2, widths = c(2.2,2) ,heights = c(2.2,2))
```

***
[W09: Draft]

With the previous songs in mind, I have created key- and chordograms of
top tracks from 2018 (Rosebud by U.S. Girls) and 2020 (Processed by the Boys 
by Protomartyr). 

The level of prominence of each key/chord is represent by a darker colour.

I used "norm = manhattan; distance = manhattan" for both chordograms, and
"norm = manhattan; distance = aitchison" for both keygrams.

**Need to work out my findings**

Things to consider:
Compare above to top track of years 2016 (or other/more years).


### B4: Average tempo similar over the years {data-commentary-width=300}

```{r, include = FALSE}

y2012 %>%
  summarise(mean_tempo = mean(tempo))
y2014 %>%
  summarise(mean_tempo = mean(tempo))
y2016 %>%
  summarise(mean_tempo = mean(tempo))
y2018 %>%
  summarise(mean_tempo = mean(tempo))
y2020 %>%
  summarise(mean_tempo = mean(tempo))
```


```{r, echo = FALSE, message = FALSE}

combined_tempo %>%
  ggplot( 
    aes(
      x = tempo,
      fill = category
    )
  ) +
  facet_wrap(~category) +
  scale_fill_manual(values = c("#660060", "#f66d7f", "#f6a97f", "#227788", "#DD8877")) +
  geom_histogram(binwidth = 5, position = "identity", alpha = 0.5) +
  geom_vline(xintercept = 127.5315, linetype = "dashed", color = "#660066", size = 1) +
  geom_vline(xintercept = 126.4983	, linetype = "dashed", color = "#f66d7a", size = 1) +
  geom_vline(xintercept = 134.5205, linetype = "dashed", color = "#f6a97a", size = 1) +
  geom_vline(xintercept = 128.7184, linetype = "dashed", color = "#227788", size = 1) +
  geom_vline(xintercept = 125.7792, linetype = "dashed", color = "#DD8877", size = 1) +
  geom_text(
    aes(x = tempo, y = y, label = label),
    data = tibble(label = c("Setsuyakuka"),
                  angle = 90,
                  category = "2015-2016", 
                  tempo = c(200),
                  y = c(2)),
    color = "darkred",
    size = 1.5,
    family = "mono"
  ) +
  scale_y_continuous(breaks = c(0, 5, 10, 15)) + 
  theme_light() +
  labs(
    x = "Tempo (bpm)",
    y = "Number of songs",
    title = "Average tempo over the years"
  ) +
  theme_update(plot.title = element_text(hjust = 0.5)) +
  theme(
    text = element_text(family = "Bookman"),
    title = element_text(color = "gray25"),
    plot.caption = element_text(color = "gray30"),
    plot.background = element_rect(fill = "white")
  )
```

***

Unavailable: Loudness, Key, Mode, Tempo, Time Signature

On the left, you'll observe a plotted histogram containing the tempo of every song per two years.
The average tempo of every time period are similar to each other, with a range between 125 and 135 bpm.
A minor outlier is 2015-2016, which comes around 134 bpm. This correlates to 2016 having
the highest energy feature (see A3).

### B5: Tempograms {data-commentary-width=300}

```{r, include = FALSE}
tricot <- get_tidy_audio_analysis("28IqHczYgXPd2qVM2evm1J")
viet <- get_tidy_audio_analysis("58ITGKThH6gQ4qfkir8kKb")
```

```{r, include = FALSE}
#viet %>%
 # tempogram(window_size = 4, hop_size = 1, cyclic = FALSE) %>%
  #ggplot(aes(x = time - 20, y = bpm, fill = power)) +
  #geom_raster() +
  #scale_fill_viridis_c(guide = "none") +
  #labs(x = "Time (s)", y = "Tempo (BPM)", title = "Unconscious Melody by Preoccupations") +
  #theme_classic()

#tricot %>%
 # tempogram(window_size = 4, hop_size = 1, cyclic = FALSE) %>%
  #ggplot(aes(x = time, y = bpm, fill = power)) +
  #geom_raster() +
  #scale_fill_viridis_c(guide = "none") +
  #labs(x = "Time (s)", y = "Tempo (BPM)", title = "Setsuyakuka by Tricot") +
  #theme_classic()
```

![Tempograms](tempogram.jpg){width=100%}

***

For the tempogram analysis, a typical post-punk ("Unconscious Melody") and an atypical math-rock ("Setsuyakuka") song were selected to compare its rhythmic differences. The tempo of Unconscious Melody is mostly constant
around 220 bpm, with an occasional switch towards 470 bpm. 

The tempo of the song "Setsuyakuka" is, however, less constant. Although the tempo is relatively
pronounced around 380 bpm in the first half, it goes all over the place in the second. Especially between 150-220 seconds seems to be very diverse compared to the rest of the song. Listening to the song, it could be possible that the tempogram had a less hard time calculating the tempo, as that section sounds less 'noisy' than the other parts.


**Classification** {.storyboard}
===============================================================

### C1: Predicting my music listening behaviour over the years {data-commentary-width=300}

```{r, include = FALSE}
indie <-
  bind_rows(
    y2011 %>% mutate(playlist = "2011-2012"),
    y2012 %>% mutate(playlist = "2011-2012"),
    y2013 %>% mutate(playlist = "2013-2014"),
    y2014 %>% mutate(playlist = "2013-2014"),
    y2015 %>% mutate(playlist = "2015-2016"),
    y2016 %>% mutate(playlist = "2015-2016"),
    y2017 %>% mutate(playlist = "2017-2018"),
    y2018 %>% mutate(playlist = "2017-2018"),
    y2019 %>% mutate(playlist = "2019-2020"),
    y2020 %>% mutate(playlist = "2019-2020")
  ) 
```

```{r, include = FALSE, cache = FALSE}
indie_features <-
  indie %>%  # For your portfolio, change this to the name of your corpus.
  add_audio_analysis() %>% 
  mutate(
    playlist = factor(playlist),
    segments = map2(segments, key, compmus_c_transpose),
    pitches =
      map(
        segments,
        compmus_summarise, pitches,
        method = "mean", norm = "manhattan"
      ),
    timbre =
      map(
        segments,
        compmus_summarise, timbre,
        method = "mean",
      )
  ) %>%
  mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
  mutate_at(vars(pitches, timbre), map, bind_rows) %>%
  unnest(cols = c(pitches, timbre))
```

```{r, include = FALSE}
indie_recipe <-
  recipe(
    playlist ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = indie_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1]. # to include features such as loudness
```

```{r, include = FALSE}
indie_cv <- indie_features %>% vfold_cv(10) # use first 20% to test remaining 80% in chunks of 20%
```

```{r, include = FALSE}
tree_model <-
  decision_tree() %>%
  set_mode("classification") %>% 
  set_engine("C5.0")
indie_tree <- 
  workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(tree_model) %>% 
  fit_resamples(
    indie_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r, include = FALSE, cache = TRUE}
workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(tree_model) %>% 
  fit(indie_features) %>% 
  pluck("fit", "fit", "fit") %>%
  summary()
```

```{r, include = FALSE}
forest_model <-
  rand_forest() %>%
  set_mode("classification") %>% 
  set_engine("ranger", importance = "impurity")
indie_forest <- 
  workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(forest_model) %>% 
  fit_resamples(
    indie_cv, 
    control = control_resamples(save_pred = TRUE)
  )
```

```{r, include = FALSE, cache = TRUE}
indie_forest %>% get_pr()
```

```{r, echo = FALSE, cache = TRUE}
workflow() %>% 
  add_recipe(indie_recipe) %>% 
  add_model(forest_model) %>% 
  fit(indie_features) %>% 
  pluck("fit", "fit", "fit") %>%
  ranger::importance() %>% 
  enframe() %>% 
  mutate(name = fct_reorder(name, value)) %>% 
  ggplot(aes(name, value)) + 
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  labs(x = NULL, y = "Importance")

indie_forest %>% get_conf_mat() %>% autoplot(type = "heatmap")
```

***

[Draft]

Some observations

KNN matrix: \
- Periods 2011-2012, 2013-2014, and 2019-2020 are most distinctive compared to others. \
- 2017-2018 has a minor overlap with 2015-2016. In the context of my corpus, it could mean that my listening habits were similar between those years.

Random forest tree: \
- Timbre is important (c01, c03, and c11). \
- Instrumentalness is also an important factor. Could be due to math rock (usually without vocals in East Asia) and ambient music, of which both genres became prominent on my last.fm starting from 2015-2016. \

Table 1. Accuracy of random forest model:

| Group | Precision | Recall |
|:------:|:-----|:------|
| 2011-2012 | 0.444	| 0.467 |	
| 2013-2014 | 0.824 | 0.875 |
| 2015-2016 | 0.330 |	0.300 |
| 2017-2018 | 0.353 |	0.342 |	
| 2019-2020 | 0.484	| 0.492	|

To do:
Resize figures.
Make facetted plots of top features from the random forest.
Using only the top 10 most influential features and replot everything.

**Conclusions** {.storyboard}
===============================================================

Column 1
---------------------------------------------------------------

TODO

Relevant link: https://www.theverge.com/2018/2/12/17003076/spotify-data-shows-songs-teens-adult-taste-music

Column 2 
---------------------------------------------------------------
